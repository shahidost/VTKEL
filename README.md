Visual-textual-knowledge-linking (VTKL) dataset, contains documents composed of pictures with five corresponding textual captions for each image. The VTKL dataset is obtained by extending the Flikr30k dataset, designed for visual-textual mention alignment, with links to YAGO KB, one of the largest web knowledge base. These links are obtained automatically by processing each image caption with PIKES, an NLP tool for entity recognition and linking. For indepth information and accessing explore the relevent files described below.

Files:

File 'Introduction.md' describe the introduction of NLTK in details.

File 'Incorrect NER and linking mention.xlsx' consists of all error cases which are wrongly process by PIKES for NER and entites linking for VTKL dataset and the results of our evaluation.

