Visual-textual-knowledge-linking (VTKL) dataset, contains documents composed of pictures with five corresponding textual captions for each image. The VTKL dataset is obtained by extending the Flikr30k dataset, designed for visual-textual mention alignment, with links to YAGO KB, one of the largest web knowledge base. These links are obtained automatically by processing each image caption with PIKES, an NLP tool for entity recognition and linking. For indepth information and accessing explore the relevent files described below.

Files:

'Introduction.md' describe the introduction of NLTK in details.

'Incorrect NER and linking mention.xlsx' consists of all error cases which are wrongly process by PIKES for NER and entites linking for VTKL dataset and the results of our evaluation.

'300 random images for evaluations -error_free.ttl' consists of VTKL dataset for 300 randomly selected entries for VTKEL task. The error of these 300 images dataset are fixed manually by correcting each incorrect mention process by PIKES.

'https://figshare.com/account/projects/61421/articles/7882781' consists of VTKL dataset for 31781 images from Flickr30k.
